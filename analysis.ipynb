# ---------------------------------------------------
# Part 1: Load and Explore the Data
# ---------------------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud

# 1. Load metadata.csv (adjust path as needed)
df = pd.read_csv('metadata.csv')

# 2. Inspect first rows
print("First five rows:")
display(df.head())

# 3. DataFrame dimensions
print(f"Dataset contains {df.shape[0]:,} rows and {df.shape[1]} columns")

# 4. Data types
print("\nData types:")
print(df.dtypes)

# 5. Missing values
print("\nMissing values per column:")
print(df.isnull().sum())

# 6. Basic statistics for numeric columns
print("\nBasic statistics:")
display(df.describe())

# ---------------------------------------------------
# Part 2: Data Cleaning and Preparation
# ---------------------------------------------------

# Convert 'publish_time' to datetime
df['publish_time'] = pd.to_datetime(df['publish_time'], errors='coerce')

# Extract year from publication date
df['year'] = df['publish_time'].dt.year

# Example: Abstract word count (fill missing abstracts with empty string first)
df['abstract'] = df['abstract'].fillna('')
df['abstract_word_count'] = df['abstract'].apply(lambda x: len(str(x).split()))

# Decide how to handle missing values:
# We'll keep rows with at least title + publish_time
df_clean = df.dropna(subset=['title', 'publish_time'])

print(f"After cleaning: {df_clean.shape[0]:,} rows")
display(df_clean.head())


# ---------------------------------------------------
# Part 3: Basic Analysis & Visualization
# ---------------------------------------------------

# 1. Papers by publication year
year_counts = df_clean['year'].value_counts().sort_index()

plt.figure(figsize=(10,6))
plt.bar(year_counts.index, year_counts.values)
plt.title('Number of Publications by Year')
plt.xlabel('Year')
plt.ylabel('Count')
plt.show()

# 2. Top journals
top_journals = (df_clean['journal']
                .value_counts()
                .head(10))

plt.figure(figsize=(10,6))
sns.barplot(x=top_journals.values, y=top_journals.index)
plt.title('Top Journals Publishing COVID-19 Research')
plt.xlabel('Number of Papers')
plt.ylabel('Journal')
plt.show()

# 3. Most frequent words in titles (simple)
from collections import Counter
import re

titles = ' '.join(df_clean['title'].dropna().tolist()).lower()
words = re.findall(r'\b[a-z]{3,}\b', titles)  # simple word extraction
common_words = Counter(words).most_common(30)

# Word Cloud of titles
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(common_words))

plt.figure(figsize=(12,6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Most Frequent Words in Paper Titles')
plt.show()

# 4. Distribution of paper counts by source
source_counts = df_clean['source_x'].value_counts().head(10)
plt.figure(figsize=(10,6))
sns.barplot(x=source_counts.values, y=source_counts.index)
plt.title('Top Sources of Papers')
plt.xlabel('Number of Papers')
plt.ylabel('Source')
plt.show()

